{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mimic3benchmarks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmimic3benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmimic3models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Discretizer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mimic3benchmarks'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from mimic3benchmarks.mimic3models.preprocessing import Discretizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_path  = '/data1/r10user2/EHR_dataset/mimiciv_benchmark/survival_prediction'\n",
    "\n",
    "train_path = os.path.join(dir_path , 'train_listfile.csv')\n",
    "test_path = os.path.join(dir_path , 'test_listfile.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "x_train = []\n",
    "del_data = 0\n",
    "for patient_path in tqdm(train_df['stay']):\n",
    "    patient_path = os.path.join(dir_path, 'train', patient_path)\n",
    "    patient = pd.read_csv(patient_path)\n",
    "    patient = patient.fillna('')\n",
    "    data_processor = Discretizer(impute_strategy='normal_value', timestep=1)\n",
    "    data = data_processor.transform(np.array(patient))[0]\n",
    "    if data.shape[0]  < 48:\n",
    "        num_pad = 48 - data.shape[0]\n",
    "        #print(num_pad)\n",
    "        last_data = data[-1].repeat(num_pad,axis=0).reshape(-1,76)\n",
    "        #print(last_data.shape)\n",
    "        data = np.concatenate([data, last_data])\n",
    "\n",
    "    if data.shape[0] == 48:\n",
    "        x_train.append(data)\n",
    "    else:\n",
    "        del_data += 1\n",
    "       \n",
    "print(del_data) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "t_train = np.array(train_df['survival_time'])\n",
    "e_train = np.array(train_df['censor'])\n",
    "np.save(\"x_train.npy\", x_train)\n",
    "np.save(\"t_train.npy\", t_train)\n",
    "np.save(\"e_train.npy\", e_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 47.38      , 119.7       ,  22.63472222, ...,  48.59055556,\n",
       "        32.99166667,  16.94916667])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4972/4972 [00:40<00:00, 122.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "del_data = 0\n",
    "for patient_path in tqdm(test_df['stay']):\n",
    "    patient_path = os.path.join(dir_path, 'test', patient_path)\n",
    "    patient = pd.read_csv(patient_path)\n",
    "    patient = patient.fillna('')\n",
    "    data_processor = Discretizer(impute_strategy='normal_value',timestep=1)\n",
    "    data = data_processor.transform(np.array(patient))[0]\n",
    "    if data.shape[0]  < 48:\n",
    "        num_pad = 48 - data.shape[0]\n",
    "        #print(num_pad)\n",
    "        last_data = data[-1].repeat(num_pad,axis=0).reshape(-1,76)\n",
    "        #print(last_data.shape)\n",
    "        data = np.concatenate([data, last_data])\n",
    "\n",
    "    if data.shape[0] == 48:\n",
    "        x_test.append(data)\n",
    "    else:\n",
    "        del_data += 1\n",
    "       \n",
    "print(del_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "t_test = np.array(test_df['survival_time'])\n",
    "e_test = np.array(test_df['censor'])\n",
    "np.save(\"x_test.npy\", x_test)\n",
    "np.save(\"t_test.npy\", t_test)\n",
    "np.save(\"e_test.npy\", e_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18064, 48, 76)\n",
      "(18064,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('x_train.npy')\n",
    "t_train = np.load('t_train.npy')\n",
    "e_train = 1 - np.load('e_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.where(t_train <= 0)[0]\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17961, 48, 76)\n"
     ]
    }
   ],
   "source": [
    "t_train = np.delete(t_train, index)\n",
    "e_train = np.delete(e_train, index)\n",
    "x_train = np.delete(x_train, index, axis=0)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11747675519180446\n"
     ]
    }
   ],
   "source": [
    "print(e_train.sum()/len(e_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(t_train <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      " 98%|█████████▊| 9831/10000 [01:51<00:01, 88.23it/s] \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (48) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m DeepSurvivalMachines(\n\u001b[1;32m     10\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     11\u001b[0m     distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# The fit method is called to train the model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Jiacheng/dspm-auton-survival/auton_survival/models/dsm/__init__.py:260\u001b[0m, in \u001b[0;36mDSMBase.fit\u001b[0;34m(self, x, t, e, vsize, val_data, iters, learning_rate, batch_size, elbo, optimizer)\u001b[0m\n\u001b[1;32m    258\u001b[0m maxrisk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mnanmax(e_train\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m    259\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_torch_model(inputdim, optimizer, risks\u001b[38;5;241m=\u001b[39mmaxrisk)\n\u001b[0;32m--> 260\u001b[0m model, _, trained_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43melbo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melbo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_weights \u001b[38;5;241m=\u001b[39m trained_weights\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Documents/Jiacheng/dspm-auton-survival/auton_survival/models/dsm/utilities.py:178\u001b[0m, in \u001b[0;36mtrain_dsm\u001b[0;34m(model, x_train, t_train, e_train, x_valid, t_valid, e_valid, n_iter, lr, elbo, bs, random_seed)\u001b[0m\n\u001b[1;32m    176\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mrisks):\n\u001b[0;32m--> 178\u001b[0m   batch_weights, batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m_reshape_tensor_with_nans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m_reshape_tensor_with_nans\u001b[49m\u001b[43m(\u001b[49m\u001b[43meb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                              \u001b[49m\u001b[43melbo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melbo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mrisk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m   loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m    185\u001b[0m   cur_weights\u001b[38;5;241m.\u001b[39mappend(batch_weights\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Documents/Jiacheng/dspm-auton-survival/auton_survival/models/dsm/losses.py:278\u001b[0m, in \u001b[0;36mconditional_loss\u001b[0;34m(model, x, t, e, elbo, risk)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _conditional_weibull_loss(model, x, t, e, elbo, risk)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdist \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogNormal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_conditional_lognormal_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melbo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrisk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdist \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _conditional_normal_loss(model, x, t, e, elbo, risk)\n",
      "File \u001b[0;32m~/Documents/Jiacheng/dspm-auton-survival/auton_survival/models/dsm/losses.py:178\u001b[0m, in \u001b[0;36m_conditional_lognormal_loss\u001b[0;34m(model, x, t, e, elbo, risk)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conditional_lognormal_loss\u001b[39m(model, x, t, e, elbo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, risk\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    177\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdiscount\n\u001b[0;32m--> 178\u001b[0m     shape, scale, logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrisk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     lossf \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    181\u001b[0m     losss \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Jiacheng/dspm-auton-survival/auton_survival/models/dsm/dsm_torch.py:217\u001b[0m, in \u001b[0;36mDeepSurvivalMachinesTorch.forward\u001b[0;34m(self, x, risk)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# xrep = torch.mean(xrep, dim=1)\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# print(xrep.shape)\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m#print(torch.isnan(xrep))\u001b[39;00m\n\u001b[1;32m    216\u001b[0m dim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshapeg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrisk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrisk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    218\u001b[0m        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaleg[risk](xrep))\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale[risk]\u001b[38;5;241m.\u001b[39mexpand(dim, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    219\u001b[0m        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate[risk](xrep)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (48) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "from auton_survival.models.dsm import DeepRecurrentSurvivalMachines\n",
    "from auton_survival.models.dsm import DeepSurvivalMachines\n",
    "\n",
    "# model = DeepRecurrentSurvivalMachines(k=3,\n",
    "#                distribution='LogNormal',\n",
    "#                layers=10)\n",
    "model = DeepSurvivalMachines(\n",
    "    k=1,\n",
    "    distribution=\"LogNormal\",\n",
    "    layers=[100]\n",
    ")\n",
    "# The fit method is called to train the model\n",
    "model.fit(x_train, t_train, e_train, iters=100, learning_rate=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 15267, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trained_weights = model.trained_weights\n",
    "print(trained_weights.shape)\n",
    "print(np.isnan(trained_weights).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4972, 48, 76)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_test = np.load('x_test.npy')\n",
    "t_test = np.load('t_test.npy')\n",
    "e_test = 1 - np.load('e_test.npy')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22933, 48, 76)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.concatenate((t_test , t_train),axis=0)\n",
    "e = np.concatenate((e_test , e_train),axis=0)\n",
    "x = np.concatenate((x_test , x_train),axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4972, 4)\n",
      "For 0.25 quantile\n",
      "TD Concordance Index: 0.7501109140105855\n",
      "Brier Score: 0.04374365045897336\n",
      "ROC AUC  0.7275706406956468 \n",
      "\n",
      "For 0.5 quantile\n",
      "TD Concordance Index: 0.6942621255117725\n",
      "Brier Score: 0.10662817214287049\n",
      "ROC AUC  0.6505921963917142 \n",
      "\n",
      "For 0.75 quantile\n",
      "TD Concordance Index: 0.6499962178672913\n",
      "Brier Score: 0.20011246862156407\n",
      "ROC AUC  0.6061074770174052 \n",
      "\n",
      "For 0.9 quantile\n",
      "TD Concordance Index: 0.6170279008490849\n",
      "Brier Score: 0.24163905949422967\n",
      "ROC AUC  0.5784667048214809 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [0.25, 0.5, 0.75, 0.9]\n",
    "times = np.quantile(t[e == 1], horizons).tolist()\n",
    "# print(times)\n",
    "out_risk = model.predict_risk(x_test, times)\n",
    "print(out_risk.shape)\n",
    "out_survival = model.predict_survival(x_test, times)\n",
    "# print(out_survival[0])\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc\n",
    "\n",
    "cis = []\n",
    "brs = []\n",
    "\n",
    "et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "# print(et_train)\n",
    "et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "# et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "#                  dtype = [('e', bool), ('t', float)])\n",
    "# print(et_train[0:10])\n",
    "for i, _ in enumerate(times):\n",
    "    cis.append(concordance_index_ipcw(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "brs.append(brier_score(et_train, et_test, out_survival, times)[1])\n",
    "roc_auc = []\n",
    "for i, _ in enumerate(times):\n",
    "    roc_auc.append(cumulative_dynamic_auc(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "for horizon in enumerate(horizons):\n",
    "    print(f\"For {horizon[1]} quantile\")\n",
    "    print(\"TD Concordance Index:\", cis[horizon[0]])\n",
    "    print(\"Brier Score:\", brs[0][horizon[0]])\n",
    "    print(\"ROC AUC \", roc_auc[horizon[0]][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 97 is out of bounds for axis 0 with size 24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m iter_idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m97\u001b[39m, \u001b[38;5;241m98\u001b[39m, \u001b[38;5;241m99\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(\u001b[43mtrained_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43miter_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[:, \u001b[38;5;241m0\u001b[39m], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39maxes[idx])\n\u001b[1;32m      9\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(trained_weights[iter_idx[idx]][:, \u001b[38;5;241m1\u001b[39m], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39maxes[idx])\n\u001b[1;32m     10\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(trained_weights[iter_idx[idx]][:, \u001b[38;5;241m2\u001b[39m], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39maxes[idx])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 97 is out of bounds for axis 0 with size 24"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figs, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "iter_idx = [97, 98, 99]\n",
    "\n",
    "for idx in range(3):\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 0], fill=True, ax=axes[idx])\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 1], fill=True, ax=axes[idx])\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 2], fill=True, ax=axes[idx])\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 3], fill=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Iter {iter_idx[idx]}')\n",
    "    axes[idx].set_xlim(0.15, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(False, 2.178e+03), (False, 2.172e+03), (False, 2.190e+03),\n",
       "       ( True, 2.970e+02), (False, 2.131e+03), ( True, 1.000e+00),\n",
       "       (False, 2.122e+03), ( True, 1.496e+03), ( True, 9.200e+02),\n",
       "       (False, 2.175e+03), (False, 2.173e+03), ( True, 1.671e+03),\n",
       "       (False, 2.192e+03), ( True, 8.650e+02), (False, 2.166e+03),\n",
       "       (False, 2.168e+03), ( True, 9.050e+02), ( True, 2.353e+03),\n",
       "       (False, 2.146e+03), ( True, 6.100e+01), ( True, 2.358e+03),\n",
       "       (False, 2.114e+03), (False, 2.132e+03), (False, 2.139e+03),\n",
       "       (False, 2.048e+03), (False, 2.152e+03), ( True, 6.000e+00),\n",
       "       (False, 2.156e+03), ( True, 1.180e+02), (False, 2.064e+03),\n",
       "       ( True, 8.490e+02), ( True, 7.140e+02), (False, 2.057e+03),\n",
       "       ( True, 2.000e+00), ( True, 7.000e+00), (False, 2.151e+03),\n",
       "       ( True, 6.000e+00), ( True, 4.220e+02), ( True, 3.540e+02),\n",
       "       (False, 2.065e+03), (False, 2.048e+03), ( True, 1.065e+03),\n",
       "       ( True, 5.350e+02), (False, 2.118e+03), ( True, 9.700e+01),\n",
       "       (False, 2.113e+03), ( True, 1.000e+02), (False, 2.032e+03),\n",
       "       ( True, 1.317e+03), (False, 2.126e+03), (False, 2.126e+03),\n",
       "       (False, 2.123e+03), ( True, 6.700e+02), ( True, 3.430e+02),\n",
       "       ( True, 3.000e+00), (False, 2.009e+03), ( True, 6.400e+01),\n",
       "       (False, 1.994e+03), ( True, 1.579e+03), (False, 1.993e+03),\n",
       "       ( True, 2.000e+00), (False, 1.955e+03), ( True, 4.200e+01),\n",
       "       (False, 1.964e+03), ( True, 1.548e+03), ( True, 4.460e+02),\n",
       "       (False, 1.976e+03), (False, 2.009e+03), (False, 1.942e+03),\n",
       "       ( True, 1.000e+00), ( True, 1.510e+02), (False, 2.006e+03),\n",
       "       (False, 2.086e+03), (False, 1.969e+03), (False, 1.939e+03),\n",
       "       (False, 1.939e+03), (False, 1.940e+03), ( True, 1.576e+03),\n",
       "       (False, 1.941e+03), ( True, 1.970e+02), (False, 1.933e+03),\n",
       "       ( True, 9.500e+01), ( True, 2.160e+03), (False, 2.084e+03),\n",
       "       (False, 2.145e+03), (False, 2.125e+03), (False, 1.920e+03),\n",
       "       ( True, 4.000e+00), ( True, 1.553e+03), ( True, 2.350e+02),\n",
       "       ( True, 1.920e+02), ( True, 1.233e+03), ( True, 8.800e+01),\n",
       "       ( True, 1.954e+03), ( True, 9.030e+02), ( True, 6.120e+02),\n",
       "       (False, 2.025e+03), ( True, 2.000e+00), ( True, 7.000e+00),\n",
       "       (False, 1.887e+03), ( True, 1.870e+02), ( True, 1.010e+02),\n",
       "       (False, 1.885e+03), ( True, 9.360e+02), ( True, 3.630e+02),\n",
       "       ( True, 1.048e+03), (False, 1.977e+03), (False, 1.936e+03),\n",
       "       (False, 1.887e+03), (False, 1.889e+03), (False, 1.923e+03),\n",
       "       (False, 2.123e+03), ( True, 1.100e+01), (False, 2.100e+03),\n",
       "       (False, 1.914e+03), (False, 1.883e+03), ( True, 3.300e+01),\n",
       "       (False, 1.931e+03), ( True, 1.506e+03), (False, 1.858e+03),\n",
       "       ( True, 6.000e+00), (False, 1.854e+03), (False, 1.847e+03),\n",
       "       (False, 1.858e+03), ( True, 1.870e+02), ( True, 4.600e+01),\n",
       "       (False, 2.061e+03), (False, 1.893e+03), (False, 2.108e+03),\n",
       "       ( True, 8.300e+01), ( True, 3.300e+01), ( True, 1.377e+03),\n",
       "       (False, 1.863e+03), (False, 1.880e+03), ( True, 1.359e+03),\n",
       "       (False, 1.831e+03), (False, 1.836e+03), ( True, 1.159e+03),\n",
       "       ( True, 1.130e+02), ( True, 1.217e+03), (False, 1.899e+03),\n",
       "       (False, 1.934e+03), ( True, 1.527e+03), (False, 1.954e+03),\n",
       "       (False, 1.979e+03), ( True, 1.232e+03), (False, 2.066e+03),\n",
       "       ( True, 1.624e+03), ( True, 5.300e+02), ( True, 1.096e+03),\n",
       "       ( True, 3.450e+02), (False, 1.919e+03), ( True, 1.577e+03),\n",
       "       (False, 1.883e+03), (False, 1.904e+03), (False, 2.083e+03),\n",
       "       ( True, 1.460e+02), ( True, 2.350e+03), ( True, 1.926e+03),\n",
       "       (False, 2.114e+03), ( True, 7.180e+02), (False, 1.451e+03),\n",
       "       ( True, 3.580e+02), ( True, 4.650e+02), (False, 1.381e+03),\n",
       "       ( True, 1.100e+01), (False, 1.385e+03), (False, 1.346e+03),\n",
       "       (False, 1.338e+03), ( True, 1.370e+02), (False, 1.449e+03),\n",
       "       ( True, 1.700e+01), ( True, 1.536e+03), ( True, 1.627e+03),\n",
       "       ( True, 1.000e+01), ( True, 1.000e+00), ( True, 1.000e+00),\n",
       "       ( True, 3.130e+02), ( True, 1.200e+03), (False, 1.384e+03),\n",
       "       ( True, 1.660e+02), (False, 1.420e+03), ( True, 5.620e+02),\n",
       "       (False, 1.302e+03), (False, 1.253e+03), (False, 1.438e+03),\n",
       "       (False, 1.400e+03), (False, 1.329e+03), (False, 1.325e+03),\n",
       "       (False, 1.257e+03), (False, 1.319e+03), (False, 1.256e+03),\n",
       "       (False, 1.298e+03), ( True, 1.800e+01), (False, 1.408e+03),\n",
       "       (False, 1.333e+03), (False, 1.378e+03), (False, 1.353e+03),\n",
       "       ( True, 6.540e+02), (False, 1.262e+03), (False, 1.314e+03),\n",
       "       (False, 1.280e+03), (False, 1.308e+03), (False, 1.433e+03),\n",
       "       (False, 1.430e+03), ( True, 7.000e+00), ( True, 1.000e+00),\n",
       "       (False, 1.272e+03), (False, 1.277e+03), ( True, 1.080e+02),\n",
       "       ( True, 2.000e+00), (False, 1.409e+03), (False, 1.454e+03),\n",
       "       ( True, 1.090e+02), (False, 1.363e+03), (False, 1.374e+03),\n",
       "       (False, 1.365e+03), ( True, 6.000e+00), ( True, 2.000e+02),\n",
       "       (False, 1.336e+03), (False, 1.317e+03), ( True, 1.340e+02),\n",
       "       ( True, 5.700e+01), ( True, 1.165e+03), ( True, 1.400e+02),\n",
       "       ( True, 2.000e+01), ( True, 7.000e+00), (False, 1.190e+03),\n",
       "       ( True, 1.400e+02), ( True, 1.054e+03), (False, 1.108e+03),\n",
       "       (False, 1.106e+03), (False, 1.106e+03), ( True, 2.590e+02),\n",
       "       ( True, 1.000e+00), (False, 1.125e+03), (False, 1.162e+03),\n",
       "       (False, 1.140e+03), (False, 1.157e+03), (False, 1.231e+03),\n",
       "       ( True, 9.530e+02), (False, 1.248e+03), (False, 1.235e+03),\n",
       "       (False, 1.290e+03), ( True, 1.152e+03), ( True, 1.900e+01),\n",
       "       (False, 1.251e+03), ( True, 1.136e+03), (False, 1.182e+03),\n",
       "       ( True, 2.000e+00), ( True, 1.690e+02), ( True, 7.040e+02),\n",
       "       ( True, 1.430e+02), ( True, 2.000e+00), (False, 1.232e+03),\n",
       "       ( True, 4.790e+02), (False, 1.211e+03), (False, 1.232e+03),\n",
       "       (False, 1.223e+03), (False, 1.191e+03), ( True, 1.100e+01),\n",
       "       ( True, 1.000e+01), (False, 1.117e+03), ( True, 1.174e+03),\n",
       "       (False, 1.123e+03), ( True, 3.850e+02), (False, 1.109e+03),\n",
       "       (False, 1.098e+03), (False, 1.114e+03), ( True, 6.400e+01),\n",
       "       (False, 1.151e+03), ( True, 9.100e+01), ( True, 6.140e+02),\n",
       "       (False, 1.140e+03), ( True, 5.420e+02), (False, 1.199e+03),\n",
       "       (False, 1.248e+03), (False, 1.163e+03), ( True, 3.210e+02),\n",
       "       (False, 1.187e+03), (False, 1.207e+03), ( True, 2.950e+02),\n",
       "       (False, 1.273e+03), (False, 1.189e+03), (False, 1.234e+03),\n",
       "       ( True, 5.200e+01), (False, 1.203e+03), ( True, 1.290e+02),\n",
       "       ( True, 2.970e+02), (False, 1.458e+03), ( True, 1.170e+02),\n",
       "       ( True, 3.120e+02), (False, 1.244e+03), (False, 1.160e+03),\n",
       "       ( True, 2.870e+02), ( True, 1.377e+03), (False, 1.320e+03),\n",
       "       (False, 1.245e+03), ( True, 4.970e+02), ( True, 2.890e+02),\n",
       "       (False, 1.150e+03), (False, 1.266e+03), (False, 1.266e+03),\n",
       "       (False, 1.265e+03), (False, 1.126e+03), ( True, 2.600e+01),\n",
       "       ( True, 1.320e+02), ( True, 5.520e+02), (False, 1.444e+03),\n",
       "       ( True, 1.400e+01), (False, 1.454e+03), (False, 1.123e+03),\n",
       "       (False, 1.279e+03), (False, 1.366e+03), (False, 1.196e+03),\n",
       "       ( True, 1.350e+02), (False, 1.114e+03), ( True, 3.700e+01),\n",
       "       (False, 1.390e+03), ( True, 3.200e+01), (False, 1.187e+03),\n",
       "       (False, 1.224e+03), (False, 1.121e+03), ( True, 1.900e+01),\n",
       "       (False, 1.456e+03), (False, 1.332e+03), (False, 1.174e+03),\n",
       "       (False, 1.274e+03), ( True, 3.820e+02), (False, 1.295e+03),\n",
       "       (False, 1.102e+03), (False, 1.169e+03), (False, 1.136e+03),\n",
       "       (False, 1.105e+03), (False, 1.320e+03), ( True, 1.279e+03),\n",
       "       (False, 1.178e+03), (False, 1.170e+03), (False, 1.336e+03),\n",
       "       ( True, 2.200e+01), (False, 1.103e+03), (False, 1.107e+03),\n",
       "       (False, 1.347e+03), ( True, 6.320e+02), (False, 1.161e+03),\n",
       "       (False, 1.388e+03), ( True, 6.000e+00), ( True, 3.200e+01),\n",
       "       (False, 5.730e+02), (False, 5.500e+02), (False, 5.700e+02),\n",
       "       ( True, 1.600e+01), ( True, 5.000e+00), (False, 5.780e+02),\n",
       "       ( True, 1.000e+00), (False, 5.500e+02), (False, 5.890e+02),\n",
       "       (False, 5.420e+02), ( True, 2.260e+02), ( True, 8.100e+01),\n",
       "       (False, 5.500e+02), (False, 5.290e+02), (False, 5.230e+02),\n",
       "       (False, 5.220e+02), (False, 5.100e+02), (False, 5.240e+02),\n",
       "       (False, 4.800e+02), (False, 4.590e+02), ( True, 4.190e+02),\n",
       "       (False, 4.330e+02), (False, 4.450e+02), (False, 5.160e+02),\n",
       "       ( True, 3.400e+01), (False, 4.120e+02), (False, 3.980e+02),\n",
       "       (False, 3.970e+02), (False, 4.030e+02), (False, 3.860e+02),\n",
       "       (False, 3.760e+02), (False, 3.730e+02), (False, 3.710e+02),\n",
       "       (False, 6.590e+02), ( True, 2.330e+02), (False, 6.310e+02),\n",
       "       ( True, 6.000e+01), ( True, 5.370e+02), ( True, 4.730e+02),\n",
       "       (False, 6.750e+02), ( True, 6.460e+02), (False, 5.890e+02),\n",
       "       (False, 6.060e+02), ( True, 2.740e+02), ( True, 1.690e+02),\n",
       "       (False, 5.680e+02), ( True, 6.730e+02), ( True, 5.590e+02),\n",
       "       ( True, 9.300e+01), ( True, 5.500e+01), (False, 5.440e+02),\n",
       "       ( True, 6.490e+02), (False, 5.070e+02), (False, 5.210e+02),\n",
       "       ( True, 4.060e+02), (False, 5.870e+02), (False, 5.320e+02),\n",
       "       ( True, 5.300e+01), (False, 4.660e+02), (False, 4.420e+02),\n",
       "       ( True, 1.450e+02), ( True, 3.300e+01), (False, 4.510e+02),\n",
       "       (False, 4.970e+02), ( True, 1.700e+01), (False, 5.060e+02),\n",
       "       (False, 5.210e+02), ( True, 1.160e+02), ( True, 6.200e+01),\n",
       "       ( True, 2.690e+02), ( True, 1.100e+01), (False, 5.160e+02),\n",
       "       (False, 4.780e+02), ( True, 4.900e+01), (False, 4.860e+02),\n",
       "       ( True, 7.600e+01), ( True, 1.000e+00), (False, 5.110e+02),\n",
       "       (False, 4.580e+02), (False, 4.400e+02), (False, 4.520e+02),\n",
       "       ( True, 1.800e+01), ( True, 1.800e+01), ( True, 5.000e+00),\n",
       "       ( True, 2.000e+01), ( True, 3.920e+02), ( True, 6.900e+01),\n",
       "       ( True, 2.000e+00), ( True, 2.200e+01), (False, 4.260e+02),\n",
       "       (False, 4.490e+02), ( True, 7.000e+00), (False, 4.030e+02),\n",
       "       (False, 3.710e+02), (False, 3.680e+02), (False, 4.110e+02),\n",
       "       (False, 3.900e+02), ( True, 3.590e+02), (False, 4.080e+02),\n",
       "       (False, 4.070e+02), (False, 4.220e+02), (False, 3.760e+02),\n",
       "       ( True, 3.590e+02), ( True, 5.700e+01), ( True, 3.280e+02),\n",
       "       (False, 4.120e+02), ( True, 3.000e+00), (False, 4.580e+02),\n",
       "       (False, 4.180e+02), (False, 4.450e+02), (False, 4.590e+02),\n",
       "       ( True, 2.000e+00), (False, 4.240e+02), (False, 4.160e+02),\n",
       "       ( True, 3.000e+00), (False, 4.270e+02), (False, 4.450e+02),\n",
       "       (False, 4.210e+02), ( True, 4.000e+00), (False, 3.990e+02),\n",
       "       (False, 5.190e+02), (False, 6.090e+02), (False, 4.460e+02),\n",
       "       (False, 6.260e+02), (False, 4.450e+02), ( True, 1.900e+01),\n",
       "       (False, 4.500e+02), (False, 4.000e+02), (False, 4.580e+02),\n",
       "       (False, 5.350e+02), ( True, 4.420e+02), ( True, 4.050e+02),\n",
       "       (False, 4.570e+02), (False, 4.370e+02), (False, 5.510e+02),\n",
       "       (False, 3.710e+02), ( True, 4.670e+02), ( True, 6.440e+02),\n",
       "       (False, 3.860e+02), (False, 5.540e+02), (False, 5.730e+02),\n",
       "       (False, 4.750e+02), ( True, 3.970e+02), ( True, 1.400e+01),\n",
       "       ( True, 7.000e+00), ( True, 6.900e+01), ( True, 3.100e+01),\n",
       "       ( True, 1.000e+01), (False, 6.620e+02), (False, 7.250e+02),\n",
       "       (False, 5.320e+02), ( True, 2.590e+02)],\n",
       "      dtype=[('fstat', '?'), ('lenfol', '<f8')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.datasets import load_whas500\n",
    "X, y = load_whas500()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17961, 76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:173: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:170: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=6.8628e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=2.30423e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.67848e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.33999e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.4647e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.57181e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.25402e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.30518e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.36228e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.41323e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.47579e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.52332e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.28197e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.22503e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.11057e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.02993e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=9.91439e-18): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=9.88916e-18): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=9.89731e-18): result may not be accurate.\n",
      "  delta = solve(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6303095634116432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "x_train_avg = np.mean(x_train, axis=1)\n",
    "x_test_avg = np.mean(x_test, axis=1)\n",
    "print(x_train_avg.shape)\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "cph.fit(x_train_avg, et_train)\n",
    "pre = cph.predict(x_test_avg)\n",
    "concordance_index_ipcw(et_train, et_test, pre)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:17<00:04,  4.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<auton_survival.models.cph.DeepCoxPH at 0x7f7f074768f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from auton_survival import DeepCoxPH\n",
    "x_train_avg = np.mean(x_train, axis=1)\n",
    "\n",
    "model = DeepCoxPH(layers=[100])\n",
    "model.fit(x_train_avg, t_train, e_train, iters=100, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_avg = np.mean(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.58041666666668, 104.88333333333333, 219.08069444444445, 382.98422222222223]\n",
      "0\n",
      "[(False,  47.38      ) ( True, 119.7       ) (False,  22.63472222) ...\n",
      " ( True,  48.59055556) (False,  32.99166667) (False,  16.94916667)]\n",
      "For 0.25 quantile\n",
      "TD Concordance Index: 0.7577670480027097\n",
      "Brier Score: 0.043953331859146245\n",
      "ROC AUC  0.7360779703436262 \n",
      "\n",
      "For 0.5 quantile\n",
      "TD Concordance Index: 0.6983169711107678\n",
      "Brier Score: 0.10701804934126019\n",
      "ROC AUC  0.6528685099318772 \n",
      "\n",
      "For 0.75 quantile\n",
      "TD Concordance Index: 0.6466879811005131\n",
      "Brier Score: 0.20727602640918452\n",
      "ROC AUC  0.5946807399830735 \n",
      "\n",
      "For 0.9 quantile\n",
      "TD Concordance Index: 0.6280973480587356\n",
      "Brier Score: 0.24071580478966462\n",
      "ROC AUC  0.6026205003987266 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [0.25, 0.5, 0.75, 0.9]\n",
    "times = np.quantile(t[e == 1], horizons).tolist()\n",
    "print(times)\n",
    "out_risk = model.predict_risk(x_test_avg, times)\n",
    "print(np.isnan(out_risk).sum())\n",
    "out_survival = model.predict_survival(x_test_avg, times)\n",
    "# print(out_survival[0])\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc\n",
    "\n",
    "cis = []\n",
    "brs = []\n",
    "\n",
    "et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "print(et_train)\n",
    "et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "# et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "#                  dtype = [('e', bool), ('t', float)])\n",
    "# print(et_train[0:10])\n",
    "for i, _ in enumerate(times):\n",
    "    cis.append(concordance_index_ipcw(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "brs.append(brier_score(et_train, et_test, out_survival, times)[1])\n",
    "roc_auc = []\n",
    "for i, _ in enumerate(times):\n",
    "    roc_auc.append(cumulative_dynamic_auc(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "for horizon in enumerate(horizons):\n",
    "    print(f\"For {horizon[1]} quantile\")\n",
    "    print(\"TD Concordance Index:\", cis[horizon[0]])\n",
    "    print(\"Brier Score:\", brs[0][horizon[0]])\n",
    "    print(\"ROC AUC \", roc_auc[horizon[0]][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append('/home/r10user10/Documents/Jiacheng/dspm-auton-survival')\n",
    "\n",
    "from nfm.nfm.datasets import SurvivalDataset\n",
    "from nfm.nfm.base import FullyNeuralNLL\n",
    "from nfm.nfm.eps_config import ParetoEps\n",
    "from pycox.evaluation.eval_surv import EvalSurv\n",
    "\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=1 + data_full.num_features, out_features=128, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, y, z):\n",
    "        inputs = torch.cat([z, y], dim=1)\n",
    "        return torch.exp(self.mlp(inputs))\n",
    "\n",
    "\n",
    "data_full = SurvivalDataset.metabric('/home/r10user10/Documents/Jiacheng/dspm-auton-survival/nfm/data/metabric_IHC4_clinical_train_test.h5')\n",
    "fold_c_indices = []\n",
    "fold_ibs = []\n",
    "fold_nbll = []\n",
    "normalizing_factor = 366.25\n",
    "\n",
    "\n",
    "def normalize(y):\n",
    "    return (y + 1) / normalizing_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_full)):\n",
    "    if not data_full[i][0].is_cuda:\n",
    "        print('error')\n",
    "    if not data_full[i][1].is_cuda:\n",
    "        print('error')\n",
    "    if not data_full[i][2].is_cuda:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r10user10/Documents/Jiacheng/dspm-auton-survival/nfm/nfm/datasets.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.float, device=default_device).view(-1, 1)\n",
      "/home/r10user10/Documents/Jiacheng/dspm-auton-survival/nfm/nfm/datasets.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.delta = torch.tensor(delta, dtype=torch.float, device=default_device).view(-1, 1)\n",
      "/home/r10user10/Documents/Jiacheng/dspm-auton-survival/nfm/nfm/datasets.py:192: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.z = torch.tensor(z, dtype=torch.float, device=default_device)\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
      "  assert pd.Series(self.index_surv).is_monotonic\n",
      "  0%|          | 0/10 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nNo implementation of function Function(<built-in function max>) found for signature:\n \n >>> max(array(float64, 1d, C), float64)\n \nThere are 8 candidate implementations:\n  - Of which 6 did not match due to:\n  Overload of function 'max': File: <numerous>: Line N/A.\n    With argument(s): '(array(float64, 1d, C), float64)':\n   No match.\n  - Of which 2 did not match due to:\n  Overload in function 'iterable_max': File: numba/cpython/builtins.py: Line 648.\n    With argument(s): '(array(float64, 1d, C), float64)':\n   Rejected as the implementation raised a specific error:\n     TypingError: too many positional arguments\n  raised from /home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/numba/core/typing/templates.py:784\n\nDuring: resolving callee type: Function(<built-in function max>)\nDuring: typing of call at /home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/ipcw.py (18)\n\n\nFile \"../../../anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/ipcw.py\", line 18:\n    def _inv_cens_score_single(func, ts, durations, events, surv, censor_surv, idx_ts_surv_i,\n        <source elided>\n            g_tt = censor_surv[idx_tt_censor[i], i]\n            g_ts = max(g_ts, min_g)\n            ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 35\u001b[0m\n\u001b[1;32m     29\u001b[0m         test_evaluator \u001b[38;5;241m=\u001b[39m EvalSurv(\n\u001b[1;32m     30\u001b[0m             surv\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(surv_pred_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), index\u001b[38;5;241m=\u001b[39mtg_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()),\n\u001b[1;32m     31\u001b[0m             durations\u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     32\u001b[0m             events\u001b[38;5;241m=\u001b[39mdelta_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     33\u001b[0m             censor_surv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m         test_c_indices\u001b[38;5;241m.\u001b[39mappend(test_evaluator\u001b[38;5;241m.\u001b[39mconcordance_td(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mantolini\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 35\u001b[0m         test_ibs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtest_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrated_brier_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtg_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m         test_nbll\u001b[38;5;241m.\u001b[39mappend(test_evaluator\u001b[38;5;241m.\u001b[39mintegrated_nbll(time_grid\u001b[38;5;241m=\u001b[39mtg_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m     37\u001b[0m valid_argmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(valid_losses)\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/eval_surv.py:256\u001b[0m, in \u001b[0;36mEvalSurv.integrated_brier_score\u001b[0;34m(self, time_grid, max_weight)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcensor_surv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed to add censor_surv to compute briser score. Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_censor_est\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mipcw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrated_brier_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcensor_surv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_surv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcensor_surv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcensor_surv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/ipcw.py:84\u001b[0m, in \u001b[0;36m_integrated_inverce_censoring_weighed_metric.<locals>.metric\u001b[0;34m(time_grid, durations, events, surv, censor_surv, index_surv, index_censor, max_weight, steps_surv, steps_censor)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetric\u001b[39m(time_grid, durations, events, surv, censor_surv, index_surv, index_censor,\n\u001b[1;32m     83\u001b[0m            max_weight\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, steps_surv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, steps_censor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 84\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcensor_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_censor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_censor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     integral \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mintegrate\u001b[38;5;241m.\u001b[39msimps(scores, time_grid)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m integral \u001b[38;5;241m/\u001b[39m (time_grid[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m time_grid[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/ipcw.py:53\u001b[0m, in \u001b[0;36m_inverse_censoring_weighted_metric.<locals>.metric\u001b[0;34m(time_grid, durations, events, surv, censor_surv, index_surv, index_censor, max_weight, reduce, steps_surv, steps_censor)\u001b[0m\n\u001b[1;32m     51\u001b[0m     idx_tt_censor  \u001b[38;5;241m=\u001b[39m (idx_tt_censor \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m#  This ensures that we get G(tt-)\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43m_inv_cens_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcensor_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_ts_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_ts_censor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                 \u001b[49m\u001b[43midx_tt_censor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_indiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtyping\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nNo implementation of function Function(<built-in function max>) found for signature:\n \n >>> max(array(float64, 1d, C), float64)\n \nThere are 8 candidate implementations:\n  - Of which 6 did not match due to:\n  Overload of function 'max': File: <numerous>: Line N/A.\n    With argument(s): '(array(float64, 1d, C), float64)':\n   No match.\n  - Of which 2 did not match due to:\n  Overload in function 'iterable_max': File: numba/cpython/builtins.py: Line 648.\n    With argument(s): '(array(float64, 1d, C), float64)':\n   Rejected as the implementation raised a specific error:\n     TypingError: too many positional arguments\n  raised from /home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/numba/core/typing/templates.py:784\n\nDuring: resolving callee type: Function(<built-in function max>)\nDuring: typing of call at /home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/ipcw.py (18)\n\n\nFile \"../../../anaconda3/envs/python310/lib/python3.10/site-packages/pycox/evaluation/ipcw.py\", line 18:\n    def _inv_cens_score_single(func, ts, durations, events, surv, censor_surv, idx_ts_surv_i,\n        <source elided>\n            g_tt = censor_surv[idx_tt_censor[i], i]\n            g_ts = max(g_ts, min_g)\n            ^\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(range(10)):\n",
    "    torch.manual_seed(77+j)\n",
    "    train_folds, valid_folds, test_folds = data_full.cv_split(shuffle=True)\n",
    "    for i in range(5):\n",
    "        test_c_indices, test_ibs, test_nbll = [], [], []\n",
    "        valid_losses = []\n",
    "        nll = FullyNeuralNLL(eps_conf=ParetoEps(learnable=True), encoder=Net()).cuda()\n",
    "        optimizer = torch.optim.Adam(lr=1e-2, weight_decay=1e-3, params=nll.parameters())\n",
    "        loader = DataLoader(train_folds[i], batch_size=128)\n",
    "        for epoch in range(50):\n",
    "            for z, y, delta in loader:\n",
    "                nll.train()\n",
    "                loss = nll(z=z, y=normalize(y), delta=delta)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            nll.eval()\n",
    "            with torch.no_grad():\n",
    "                y_valid, delta_valid, z_valid = valid_folds[i].sort()\n",
    "                y_test, delta_test, z_test = test_folds[i].sort()\n",
    "                y_valid, y_test = normalize(y_valid), normalize(y_test)\n",
    "                valid_loss = nll(z_valid, y_valid, delta_valid)\n",
    "                valid_losses.append(valid_loss)\n",
    "                tg_test = np.linspace(y_test.cpu().numpy().min(), y_test.cpu().numpy().max(), 100)\n",
    "                tg_test = torch.tensor(tg_test, dtype=torch.float).view(-1, 1).cuda()\n",
    "                surv_pred_test = nll.get_survival_prediction(\n",
    "                    z_test=z_test, y_test=tg_test)\n",
    "\n",
    "                test_evaluator = EvalSurv(\n",
    "                    surv=pd.DataFrame(surv_pred_test.cpu().numpy(), index=tg_test.reshape(-1).cpu().numpy()),\n",
    "                    durations=y_test.cpu().numpy().reshape(-1),\n",
    "                    events=delta_test.cpu().numpy().reshape(-1),\n",
    "                    censor_surv='km')\n",
    "                test_c_indices.append(test_evaluator.concordance_td(method='antolini'))\n",
    "                test_ibs.append(test_evaluator.integrated_brier_score(time_grid=tg_test.cpu().numpy()))\n",
    "                test_nbll.append(test_evaluator.integrated_nbll(time_grid=tg_test.cpu().numpy()))\n",
    "        valid_argmin = np.argmin(valid_losses)\n",
    "        fold_c_indices.append(np.asarray(test_c_indices)[valid_argmin])\n",
    "        fold_ibs.append(np.asarray(test_ibs)[valid_argmin])\n",
    "        fold_nbll.append(np.asarray(test_nbll)[valid_argmin])\n",
    "\n",
    "\n",
    "report_str = f\"\"\"\n",
    "Results:\n",
    "    mean c-index: {np.asarray(fold_c_indices).mean()}\n",
    "    std c-index: {np.asarray(fold_c_indices).std()}\n",
    "    mean ibs: {np.asarray(fold_ibs).mean()}\n",
    "    std ibs: {np.asarray(fold_ibs).std()}\n",
    "    mean ibll: {np.asarray(fold_nbll).mean()}\n",
    "    std ibll: {np.asarray(fold_nbll).std()}\n",
    "\"\"\"\n",
    "print(report_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
