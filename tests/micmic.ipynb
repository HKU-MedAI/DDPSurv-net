{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18064 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18064/18064 [02:25<00:00, 124.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from mimic3benchmarks.mimic3models.preprocessing import Discretizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_path  = '/data1/r10user2/EHR_dataset/mimiciv_benchmark/survival_prediction'\n",
    "\n",
    "train_path = os.path.join(dir_path , 'train_listfile.csv')\n",
    "test_path = os.path.join(dir_path , 'test_listfile.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "x_train = []\n",
    "del_data = 0\n",
    "for patient_path in tqdm(train_df['stay']):\n",
    "    patient_path = os.path.join(dir_path, 'train', patient_path)\n",
    "    patient = pd.read_csv(patient_path)\n",
    "    patient = patient.fillna('')\n",
    "    data_processor = Discretizer(impute_strategy='normal_value', timestep=1)\n",
    "    data = data_processor.transform(np.array(patient))[0]\n",
    "    if data.shape[0]  < 48:\n",
    "        num_pad = 48 - data.shape[0]\n",
    "        #print(num_pad)\n",
    "        last_data = data[-1].repeat(num_pad,axis=0).reshape(-1,76)\n",
    "        #print(last_data.shape)\n",
    "        data = np.concatenate([data, last_data])\n",
    "\n",
    "    if data.shape[0] == 48:\n",
    "        x_train.append(data)\n",
    "    else:\n",
    "        del_data += 1\n",
    "       \n",
    "print(del_data) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "t_train = np.array(train_df['survival_time'])\n",
    "e_train = np.array(train_df['censor'])\n",
    "np.save(\"x_train.npy\", x_train)\n",
    "np.save(\"t_train.npy\", t_train)\n",
    "np.save(\"e_train.npy\", e_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 47.38      , 119.7       ,  22.63472222, ...,  48.59055556,\n",
       "        32.99166667,  16.94916667])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4972/4972 [00:37<00:00, 133.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "del_data = 0\n",
    "for patient_path in tqdm(test_df['stay']):\n",
    "    patient_path = os.path.join(dir_path, 'test', patient_path)\n",
    "    patient = pd.read_csv(patient_path)\n",
    "    patient = patient.fillna('')\n",
    "    data_processor = Discretizer(impute_strategy='normal_value',timestep=1)\n",
    "    data = data_processor.transform(np.array(patient))[0]\n",
    "    if data.shape[0]  < 48:\n",
    "        num_pad = 48 - data.shape[0]\n",
    "        #print(num_pad)\n",
    "        last_data = data[-1].repeat(num_pad,axis=0).reshape(-1,76)\n",
    "        #print(last_data.shape)\n",
    "        data = np.concatenate([data, last_data])\n",
    "\n",
    "    if data.shape[0] == 48:\n",
    "        x_test.append(data)\n",
    "    else:\n",
    "        del_data += 1\n",
    "       \n",
    "print(del_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "t_test = np.array(test_df['survival_time'])\n",
    "e_test = np.array(test_df['censor'])\n",
    "np.save(\"x_test.npy\", x_test)\n",
    "np.save(\"t_test.npy\", t_test)\n",
    "np.save(\"e_test.npy\", e_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18064, 48, 76)\n",
      "(18064,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('x_train.npy')\n",
    "t_train = np.load('t_train.npy')\n",
    "e_train = 1 - np.load('e_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.where(t_train <= 0)[0]\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17961, 48, 76)\n"
     ]
    }
   ],
   "source": [
    "t_train = np.delete(t_train, index)\n",
    "e_train = np.delete(e_train, index)\n",
    "x_train = np.delete(x_train, index, axis=0)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11747675519180446\n"
     ]
    }
   ],
   "source": [
    "print(e_train.sum()/len(e_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(t_train <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9831/10000 [01:11<00:01, 138.20it/s]\n",
      " 23%|██▎       | 23/100 [39:07<2:10:58, 102.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<auton_survival.models.dsm.DeepSurvivalMachines at 0x7f7f0526f970>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "from auton_survival.models.dsm import DeepRecurrentSurvivalMachines\n",
    "from auton_survival.models.dsm import DeepSurvivalMachines\n",
    "\n",
    "# model = DeepRecurrentSurvivalMachines(k=3,\n",
    "#                distribution='LogNormal',\n",
    "#                layers=10)\n",
    "model = DeepSurvivalMachines(\n",
    "    k=1,\n",
    "    distribution=\"LogNormal\",\n",
    "    layers=[100]\n",
    ")\n",
    "# The fit method is called to train the model\n",
    "model.fit(x_train, t_train, e_train, iters=100, learning_rate=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 15267, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trained_weights = model.trained_weights\n",
    "print(trained_weights.shape)\n",
    "print(np.isnan(trained_weights).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4972, 48, 76)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_test = np.load('x_test.npy')\n",
    "t_test = np.load('t_test.npy')\n",
    "e_test = 1 - np.load('e_test.npy')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22933, 48, 76)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.concatenate((t_test , t_train),axis=0)\n",
    "e = np.concatenate((e_test , e_train),axis=0)\n",
    "x = np.concatenate((x_test , x_train),axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4972, 4)\n",
      "For 0.25 quantile\n",
      "TD Concordance Index: 0.7501109140105855\n",
      "Brier Score: 0.04374365045897336\n",
      "ROC AUC  0.7275706406956468 \n",
      "\n",
      "For 0.5 quantile\n",
      "TD Concordance Index: 0.6942621255117725\n",
      "Brier Score: 0.10662817214287049\n",
      "ROC AUC  0.6505921963917142 \n",
      "\n",
      "For 0.75 quantile\n",
      "TD Concordance Index: 0.6499962178672913\n",
      "Brier Score: 0.20011246862156407\n",
      "ROC AUC  0.6061074770174052 \n",
      "\n",
      "For 0.9 quantile\n",
      "TD Concordance Index: 0.6170279008490849\n",
      "Brier Score: 0.24163905949422967\n",
      "ROC AUC  0.5784667048214809 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [0.25, 0.5, 0.75, 0.9]\n",
    "times = np.quantile(t[e == 1], horizons).tolist()\n",
    "# print(times)\n",
    "out_risk = model.predict_risk(x_test, times)\n",
    "print(out_risk.shape)\n",
    "out_survival = model.predict_survival(x_test, times)\n",
    "# print(out_survival[0])\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc\n",
    "\n",
    "cis = []\n",
    "brs = []\n",
    "\n",
    "et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "# print(et_train)\n",
    "et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "# et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "#                  dtype = [('e', bool), ('t', float)])\n",
    "# print(et_train[0:10])\n",
    "for i, _ in enumerate(times):\n",
    "    cis.append(concordance_index_ipcw(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "brs.append(brier_score(et_train, et_test, out_survival, times)[1])\n",
    "roc_auc = []\n",
    "for i, _ in enumerate(times):\n",
    "    roc_auc.append(cumulative_dynamic_auc(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "for horizon in enumerate(horizons):\n",
    "    print(f\"For {horizon[1]} quantile\")\n",
    "    print(\"TD Concordance Index:\", cis[horizon[0]])\n",
    "    print(\"Brier Score:\", brs[0][horizon[0]])\n",
    "    print(\"ROC AUC \", roc_auc[horizon[0]][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 97 is out of bounds for axis 0 with size 24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m iter_idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m97\u001b[39m, \u001b[38;5;241m98\u001b[39m, \u001b[38;5;241m99\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(\u001b[43mtrained_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43miter_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[:, \u001b[38;5;241m0\u001b[39m], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39maxes[idx])\n\u001b[1;32m      9\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(trained_weights[iter_idx[idx]][:, \u001b[38;5;241m1\u001b[39m], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39maxes[idx])\n\u001b[1;32m     10\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(trained_weights[iter_idx[idx]][:, \u001b[38;5;241m2\u001b[39m], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39maxes[idx])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 97 is out of bounds for axis 0 with size 24"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figs, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "iter_idx = [97, 98, 99]\n",
    "\n",
    "for idx in range(3):\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 0], fill=True, ax=axes[idx])\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 1], fill=True, ax=axes[idx])\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 2], fill=True, ax=axes[idx])\n",
    "    sns.kdeplot(trained_weights[iter_idx[idx]][:, 3], fill=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Iter {iter_idx[idx]}')\n",
    "    axes[idx].set_xlim(0.15, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(False, 2.178e+03), (False, 2.172e+03), (False, 2.190e+03),\n",
       "       ( True, 2.970e+02), (False, 2.131e+03), ( True, 1.000e+00),\n",
       "       (False, 2.122e+03), ( True, 1.496e+03), ( True, 9.200e+02),\n",
       "       (False, 2.175e+03), (False, 2.173e+03), ( True, 1.671e+03),\n",
       "       (False, 2.192e+03), ( True, 8.650e+02), (False, 2.166e+03),\n",
       "       (False, 2.168e+03), ( True, 9.050e+02), ( True, 2.353e+03),\n",
       "       (False, 2.146e+03), ( True, 6.100e+01), ( True, 2.358e+03),\n",
       "       (False, 2.114e+03), (False, 2.132e+03), (False, 2.139e+03),\n",
       "       (False, 2.048e+03), (False, 2.152e+03), ( True, 6.000e+00),\n",
       "       (False, 2.156e+03), ( True, 1.180e+02), (False, 2.064e+03),\n",
       "       ( True, 8.490e+02), ( True, 7.140e+02), (False, 2.057e+03),\n",
       "       ( True, 2.000e+00), ( True, 7.000e+00), (False, 2.151e+03),\n",
       "       ( True, 6.000e+00), ( True, 4.220e+02), ( True, 3.540e+02),\n",
       "       (False, 2.065e+03), (False, 2.048e+03), ( True, 1.065e+03),\n",
       "       ( True, 5.350e+02), (False, 2.118e+03), ( True, 9.700e+01),\n",
       "       (False, 2.113e+03), ( True, 1.000e+02), (False, 2.032e+03),\n",
       "       ( True, 1.317e+03), (False, 2.126e+03), (False, 2.126e+03),\n",
       "       (False, 2.123e+03), ( True, 6.700e+02), ( True, 3.430e+02),\n",
       "       ( True, 3.000e+00), (False, 2.009e+03), ( True, 6.400e+01),\n",
       "       (False, 1.994e+03), ( True, 1.579e+03), (False, 1.993e+03),\n",
       "       ( True, 2.000e+00), (False, 1.955e+03), ( True, 4.200e+01),\n",
       "       (False, 1.964e+03), ( True, 1.548e+03), ( True, 4.460e+02),\n",
       "       (False, 1.976e+03), (False, 2.009e+03), (False, 1.942e+03),\n",
       "       ( True, 1.000e+00), ( True, 1.510e+02), (False, 2.006e+03),\n",
       "       (False, 2.086e+03), (False, 1.969e+03), (False, 1.939e+03),\n",
       "       (False, 1.939e+03), (False, 1.940e+03), ( True, 1.576e+03),\n",
       "       (False, 1.941e+03), ( True, 1.970e+02), (False, 1.933e+03),\n",
       "       ( True, 9.500e+01), ( True, 2.160e+03), (False, 2.084e+03),\n",
       "       (False, 2.145e+03), (False, 2.125e+03), (False, 1.920e+03),\n",
       "       ( True, 4.000e+00), ( True, 1.553e+03), ( True, 2.350e+02),\n",
       "       ( True, 1.920e+02), ( True, 1.233e+03), ( True, 8.800e+01),\n",
       "       ( True, 1.954e+03), ( True, 9.030e+02), ( True, 6.120e+02),\n",
       "       (False, 2.025e+03), ( True, 2.000e+00), ( True, 7.000e+00),\n",
       "       (False, 1.887e+03), ( True, 1.870e+02), ( True, 1.010e+02),\n",
       "       (False, 1.885e+03), ( True, 9.360e+02), ( True, 3.630e+02),\n",
       "       ( True, 1.048e+03), (False, 1.977e+03), (False, 1.936e+03),\n",
       "       (False, 1.887e+03), (False, 1.889e+03), (False, 1.923e+03),\n",
       "       (False, 2.123e+03), ( True, 1.100e+01), (False, 2.100e+03),\n",
       "       (False, 1.914e+03), (False, 1.883e+03), ( True, 3.300e+01),\n",
       "       (False, 1.931e+03), ( True, 1.506e+03), (False, 1.858e+03),\n",
       "       ( True, 6.000e+00), (False, 1.854e+03), (False, 1.847e+03),\n",
       "       (False, 1.858e+03), ( True, 1.870e+02), ( True, 4.600e+01),\n",
       "       (False, 2.061e+03), (False, 1.893e+03), (False, 2.108e+03),\n",
       "       ( True, 8.300e+01), ( True, 3.300e+01), ( True, 1.377e+03),\n",
       "       (False, 1.863e+03), (False, 1.880e+03), ( True, 1.359e+03),\n",
       "       (False, 1.831e+03), (False, 1.836e+03), ( True, 1.159e+03),\n",
       "       ( True, 1.130e+02), ( True, 1.217e+03), (False, 1.899e+03),\n",
       "       (False, 1.934e+03), ( True, 1.527e+03), (False, 1.954e+03),\n",
       "       (False, 1.979e+03), ( True, 1.232e+03), (False, 2.066e+03),\n",
       "       ( True, 1.624e+03), ( True, 5.300e+02), ( True, 1.096e+03),\n",
       "       ( True, 3.450e+02), (False, 1.919e+03), ( True, 1.577e+03),\n",
       "       (False, 1.883e+03), (False, 1.904e+03), (False, 2.083e+03),\n",
       "       ( True, 1.460e+02), ( True, 2.350e+03), ( True, 1.926e+03),\n",
       "       (False, 2.114e+03), ( True, 7.180e+02), (False, 1.451e+03),\n",
       "       ( True, 3.580e+02), ( True, 4.650e+02), (False, 1.381e+03),\n",
       "       ( True, 1.100e+01), (False, 1.385e+03), (False, 1.346e+03),\n",
       "       (False, 1.338e+03), ( True, 1.370e+02), (False, 1.449e+03),\n",
       "       ( True, 1.700e+01), ( True, 1.536e+03), ( True, 1.627e+03),\n",
       "       ( True, 1.000e+01), ( True, 1.000e+00), ( True, 1.000e+00),\n",
       "       ( True, 3.130e+02), ( True, 1.200e+03), (False, 1.384e+03),\n",
       "       ( True, 1.660e+02), (False, 1.420e+03), ( True, 5.620e+02),\n",
       "       (False, 1.302e+03), (False, 1.253e+03), (False, 1.438e+03),\n",
       "       (False, 1.400e+03), (False, 1.329e+03), (False, 1.325e+03),\n",
       "       (False, 1.257e+03), (False, 1.319e+03), (False, 1.256e+03),\n",
       "       (False, 1.298e+03), ( True, 1.800e+01), (False, 1.408e+03),\n",
       "       (False, 1.333e+03), (False, 1.378e+03), (False, 1.353e+03),\n",
       "       ( True, 6.540e+02), (False, 1.262e+03), (False, 1.314e+03),\n",
       "       (False, 1.280e+03), (False, 1.308e+03), (False, 1.433e+03),\n",
       "       (False, 1.430e+03), ( True, 7.000e+00), ( True, 1.000e+00),\n",
       "       (False, 1.272e+03), (False, 1.277e+03), ( True, 1.080e+02),\n",
       "       ( True, 2.000e+00), (False, 1.409e+03), (False, 1.454e+03),\n",
       "       ( True, 1.090e+02), (False, 1.363e+03), (False, 1.374e+03),\n",
       "       (False, 1.365e+03), ( True, 6.000e+00), ( True, 2.000e+02),\n",
       "       (False, 1.336e+03), (False, 1.317e+03), ( True, 1.340e+02),\n",
       "       ( True, 5.700e+01), ( True, 1.165e+03), ( True, 1.400e+02),\n",
       "       ( True, 2.000e+01), ( True, 7.000e+00), (False, 1.190e+03),\n",
       "       ( True, 1.400e+02), ( True, 1.054e+03), (False, 1.108e+03),\n",
       "       (False, 1.106e+03), (False, 1.106e+03), ( True, 2.590e+02),\n",
       "       ( True, 1.000e+00), (False, 1.125e+03), (False, 1.162e+03),\n",
       "       (False, 1.140e+03), (False, 1.157e+03), (False, 1.231e+03),\n",
       "       ( True, 9.530e+02), (False, 1.248e+03), (False, 1.235e+03),\n",
       "       (False, 1.290e+03), ( True, 1.152e+03), ( True, 1.900e+01),\n",
       "       (False, 1.251e+03), ( True, 1.136e+03), (False, 1.182e+03),\n",
       "       ( True, 2.000e+00), ( True, 1.690e+02), ( True, 7.040e+02),\n",
       "       ( True, 1.430e+02), ( True, 2.000e+00), (False, 1.232e+03),\n",
       "       ( True, 4.790e+02), (False, 1.211e+03), (False, 1.232e+03),\n",
       "       (False, 1.223e+03), (False, 1.191e+03), ( True, 1.100e+01),\n",
       "       ( True, 1.000e+01), (False, 1.117e+03), ( True, 1.174e+03),\n",
       "       (False, 1.123e+03), ( True, 3.850e+02), (False, 1.109e+03),\n",
       "       (False, 1.098e+03), (False, 1.114e+03), ( True, 6.400e+01),\n",
       "       (False, 1.151e+03), ( True, 9.100e+01), ( True, 6.140e+02),\n",
       "       (False, 1.140e+03), ( True, 5.420e+02), (False, 1.199e+03),\n",
       "       (False, 1.248e+03), (False, 1.163e+03), ( True, 3.210e+02),\n",
       "       (False, 1.187e+03), (False, 1.207e+03), ( True, 2.950e+02),\n",
       "       (False, 1.273e+03), (False, 1.189e+03), (False, 1.234e+03),\n",
       "       ( True, 5.200e+01), (False, 1.203e+03), ( True, 1.290e+02),\n",
       "       ( True, 2.970e+02), (False, 1.458e+03), ( True, 1.170e+02),\n",
       "       ( True, 3.120e+02), (False, 1.244e+03), (False, 1.160e+03),\n",
       "       ( True, 2.870e+02), ( True, 1.377e+03), (False, 1.320e+03),\n",
       "       (False, 1.245e+03), ( True, 4.970e+02), ( True, 2.890e+02),\n",
       "       (False, 1.150e+03), (False, 1.266e+03), (False, 1.266e+03),\n",
       "       (False, 1.265e+03), (False, 1.126e+03), ( True, 2.600e+01),\n",
       "       ( True, 1.320e+02), ( True, 5.520e+02), (False, 1.444e+03),\n",
       "       ( True, 1.400e+01), (False, 1.454e+03), (False, 1.123e+03),\n",
       "       (False, 1.279e+03), (False, 1.366e+03), (False, 1.196e+03),\n",
       "       ( True, 1.350e+02), (False, 1.114e+03), ( True, 3.700e+01),\n",
       "       (False, 1.390e+03), ( True, 3.200e+01), (False, 1.187e+03),\n",
       "       (False, 1.224e+03), (False, 1.121e+03), ( True, 1.900e+01),\n",
       "       (False, 1.456e+03), (False, 1.332e+03), (False, 1.174e+03),\n",
       "       (False, 1.274e+03), ( True, 3.820e+02), (False, 1.295e+03),\n",
       "       (False, 1.102e+03), (False, 1.169e+03), (False, 1.136e+03),\n",
       "       (False, 1.105e+03), (False, 1.320e+03), ( True, 1.279e+03),\n",
       "       (False, 1.178e+03), (False, 1.170e+03), (False, 1.336e+03),\n",
       "       ( True, 2.200e+01), (False, 1.103e+03), (False, 1.107e+03),\n",
       "       (False, 1.347e+03), ( True, 6.320e+02), (False, 1.161e+03),\n",
       "       (False, 1.388e+03), ( True, 6.000e+00), ( True, 3.200e+01),\n",
       "       (False, 5.730e+02), (False, 5.500e+02), (False, 5.700e+02),\n",
       "       ( True, 1.600e+01), ( True, 5.000e+00), (False, 5.780e+02),\n",
       "       ( True, 1.000e+00), (False, 5.500e+02), (False, 5.890e+02),\n",
       "       (False, 5.420e+02), ( True, 2.260e+02), ( True, 8.100e+01),\n",
       "       (False, 5.500e+02), (False, 5.290e+02), (False, 5.230e+02),\n",
       "       (False, 5.220e+02), (False, 5.100e+02), (False, 5.240e+02),\n",
       "       (False, 4.800e+02), (False, 4.590e+02), ( True, 4.190e+02),\n",
       "       (False, 4.330e+02), (False, 4.450e+02), (False, 5.160e+02),\n",
       "       ( True, 3.400e+01), (False, 4.120e+02), (False, 3.980e+02),\n",
       "       (False, 3.970e+02), (False, 4.030e+02), (False, 3.860e+02),\n",
       "       (False, 3.760e+02), (False, 3.730e+02), (False, 3.710e+02),\n",
       "       (False, 6.590e+02), ( True, 2.330e+02), (False, 6.310e+02),\n",
       "       ( True, 6.000e+01), ( True, 5.370e+02), ( True, 4.730e+02),\n",
       "       (False, 6.750e+02), ( True, 6.460e+02), (False, 5.890e+02),\n",
       "       (False, 6.060e+02), ( True, 2.740e+02), ( True, 1.690e+02),\n",
       "       (False, 5.680e+02), ( True, 6.730e+02), ( True, 5.590e+02),\n",
       "       ( True, 9.300e+01), ( True, 5.500e+01), (False, 5.440e+02),\n",
       "       ( True, 6.490e+02), (False, 5.070e+02), (False, 5.210e+02),\n",
       "       ( True, 4.060e+02), (False, 5.870e+02), (False, 5.320e+02),\n",
       "       ( True, 5.300e+01), (False, 4.660e+02), (False, 4.420e+02),\n",
       "       ( True, 1.450e+02), ( True, 3.300e+01), (False, 4.510e+02),\n",
       "       (False, 4.970e+02), ( True, 1.700e+01), (False, 5.060e+02),\n",
       "       (False, 5.210e+02), ( True, 1.160e+02), ( True, 6.200e+01),\n",
       "       ( True, 2.690e+02), ( True, 1.100e+01), (False, 5.160e+02),\n",
       "       (False, 4.780e+02), ( True, 4.900e+01), (False, 4.860e+02),\n",
       "       ( True, 7.600e+01), ( True, 1.000e+00), (False, 5.110e+02),\n",
       "       (False, 4.580e+02), (False, 4.400e+02), (False, 4.520e+02),\n",
       "       ( True, 1.800e+01), ( True, 1.800e+01), ( True, 5.000e+00),\n",
       "       ( True, 2.000e+01), ( True, 3.920e+02), ( True, 6.900e+01),\n",
       "       ( True, 2.000e+00), ( True, 2.200e+01), (False, 4.260e+02),\n",
       "       (False, 4.490e+02), ( True, 7.000e+00), (False, 4.030e+02),\n",
       "       (False, 3.710e+02), (False, 3.680e+02), (False, 4.110e+02),\n",
       "       (False, 3.900e+02), ( True, 3.590e+02), (False, 4.080e+02),\n",
       "       (False, 4.070e+02), (False, 4.220e+02), (False, 3.760e+02),\n",
       "       ( True, 3.590e+02), ( True, 5.700e+01), ( True, 3.280e+02),\n",
       "       (False, 4.120e+02), ( True, 3.000e+00), (False, 4.580e+02),\n",
       "       (False, 4.180e+02), (False, 4.450e+02), (False, 4.590e+02),\n",
       "       ( True, 2.000e+00), (False, 4.240e+02), (False, 4.160e+02),\n",
       "       ( True, 3.000e+00), (False, 4.270e+02), (False, 4.450e+02),\n",
       "       (False, 4.210e+02), ( True, 4.000e+00), (False, 3.990e+02),\n",
       "       (False, 5.190e+02), (False, 6.090e+02), (False, 4.460e+02),\n",
       "       (False, 6.260e+02), (False, 4.450e+02), ( True, 1.900e+01),\n",
       "       (False, 4.500e+02), (False, 4.000e+02), (False, 4.580e+02),\n",
       "       (False, 5.350e+02), ( True, 4.420e+02), ( True, 4.050e+02),\n",
       "       (False, 4.570e+02), (False, 4.370e+02), (False, 5.510e+02),\n",
       "       (False, 3.710e+02), ( True, 4.670e+02), ( True, 6.440e+02),\n",
       "       (False, 3.860e+02), (False, 5.540e+02), (False, 5.730e+02),\n",
       "       (False, 4.750e+02), ( True, 3.970e+02), ( True, 1.400e+01),\n",
       "       ( True, 7.000e+00), ( True, 6.900e+01), ( True, 3.100e+01),\n",
       "       ( True, 1.000e+01), (False, 6.620e+02), (False, 7.250e+02),\n",
       "       (False, 5.320e+02), ( True, 2.590e+02)],\n",
       "      dtype=[('fstat', '?'), ('lenfol', '<f8')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.datasets import load_whas500\n",
    "X, y = load_whas500()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17961, 76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:173: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set += np.exp(xw[k])\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:170: RuntimeWarning: overflow encountered in exp\n",
      "  risk_set2 += np.exp(xw[k])\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=6.8628e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=2.30423e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.67848e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.33999e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.4647e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.57181e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.25402e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.30518e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.36228e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.41323e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.47579e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.52332e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.28197e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.22503e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.11057e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=1.02993e-17): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=9.91439e-18): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=9.88916e-18): result may not be accurate.\n",
      "  delta = solve(\n",
      "/home/r10user10/Documents/anaconda3/envs/python310/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449: LinAlgWarning: Ill-conditioned matrix (rcond=9.89731e-18): result may not be accurate.\n",
      "  delta = solve(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6303095634116432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "x_train_avg = np.mean(x_train, axis=1)\n",
    "x_test_avg = np.mean(x_test, axis=1)\n",
    "print(x_train_avg.shape)\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "cph.fit(x_train_avg, et_train)\n",
    "pre = cph.predict(x_test_avg)\n",
    "concordance_index_ipcw(et_train, et_test, pre)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:17<00:04,  4.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<auton_survival.models.cph.DeepCoxPH at 0x7f7f074768f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from auton_survival import DeepCoxPH\n",
    "x_train_avg = np.mean(x_train, axis=1)\n",
    "\n",
    "model = DeepCoxPH(layers=[100])\n",
    "model.fit(x_train_avg, t_train, e_train, iters=100, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_avg = np.mean(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.58041666666668, 104.88333333333333, 219.08069444444445, 382.98422222222223]\n",
      "0\n",
      "[(False,  47.38      ) ( True, 119.7       ) (False,  22.63472222) ...\n",
      " ( True,  48.59055556) (False,  32.99166667) (False,  16.94916667)]\n",
      "For 0.25 quantile\n",
      "TD Concordance Index: 0.7577670480027097\n",
      "Brier Score: 0.043953331859146245\n",
      "ROC AUC  0.7360779703436262 \n",
      "\n",
      "For 0.5 quantile\n",
      "TD Concordance Index: 0.6983169711107678\n",
      "Brier Score: 0.10701804934126019\n",
      "ROC AUC  0.6528685099318772 \n",
      "\n",
      "For 0.75 quantile\n",
      "TD Concordance Index: 0.6466879811005131\n",
      "Brier Score: 0.20727602640918452\n",
      "ROC AUC  0.5946807399830735 \n",
      "\n",
      "For 0.9 quantile\n",
      "TD Concordance Index: 0.6280973480587356\n",
      "Brier Score: 0.24071580478966462\n",
      "ROC AUC  0.6026205003987266 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [0.25, 0.5, 0.75, 0.9]\n",
    "times = np.quantile(t[e == 1], horizons).tolist()\n",
    "print(times)\n",
    "out_risk = model.predict_risk(x_test_avg, times)\n",
    "print(np.isnan(out_risk).sum())\n",
    "out_survival = model.predict_survival(x_test_avg, times)\n",
    "# print(out_survival[0])\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc\n",
    "\n",
    "cis = []\n",
    "brs = []\n",
    "\n",
    "et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "print(et_train)\n",
    "et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "# et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "#                  dtype = [('e', bool), ('t', float)])\n",
    "# print(et_train[0:10])\n",
    "for i, _ in enumerate(times):\n",
    "    cis.append(concordance_index_ipcw(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "brs.append(brier_score(et_train, et_test, out_survival, times)[1])\n",
    "roc_auc = []\n",
    "for i, _ in enumerate(times):\n",
    "    roc_auc.append(cumulative_dynamic_auc(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "for horizon in enumerate(horizons):\n",
    "    print(f\"For {horizon[1]} quantile\")\n",
    "    print(\"TD Concordance Index:\", cis[horizon[0]])\n",
    "    print(\"Brier Score:\", brs[0][horizon[0]])\n",
    "    print(\"ROC AUC \", roc_auc[horizon[0]][0], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
